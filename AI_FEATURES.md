# Funcionalidades de IA en CoachingIA

## üöÄ Generaci√≥n Autom√°tica de Objetivos

### ¬øQu√© hace?

El sistema utiliza **Ollama** con el modelo **Llama 3.1 8B** para generar objetivos autom√°ticamente bas√°ndose en:

- **Objetivo principal** del cliente
- **Enfoque** (focus) del cliente
- **Biograf√≠a** y contexto personal
- **Historial** de objetivos anteriores
- **M√©tricas** de rendimiento (sesiones completadas, calificaciones)
- **Notas** del coach

### Ventajas

‚úÖ **Ahorra tiempo**: Genera objetivos en segundos vs. minutos manualmente  
‚úÖ **Consistencia**: Mantiene un est√°ndar de calidad  
‚úÖ **Personalizaci√≥n**: Se adapta al contexto espec√≠fico del cliente  
‚úÖ **Escalabilidad**: Puede manejar m√∫ltiples clientes simult√°neamente  
‚úÖ **Privacidad**: Todo se procesa localmente  

## üìÅ Archivos Implementados

### Servicios de IA
- `src/lib/services/ai-service.ts` - Servicio principal de IA
- `src/app/api/ai/generate-goals/route.ts` - API endpoint para generar objetivos

### Componentes de UI
- `src/components/ui/ai-goals-generator.tsx` - Modal para generar objetivos
- Integrado en `src/components/client-detail.tsx` - Bot√≥n "IA" en la pesta√±a de objetivos

### Utilidades
- `scripts/check-ollama.js` - Script para verificar instalaci√≥n de Ollama
- `OLLAMA_SETUP.md` - Gu√≠a completa de instalaci√≥n
- `AI_FEATURES.md` - Esta documentaci√≥n

## üîß Configuraci√≥n R√°pida

### 1. Instalar Ollama
```bash
# Descargar desde https://ollama.ai
# O usar curl (Linux/macOS)
curl -fsSL https://ollama.ai/install.sh | sh
```

### 2. Descargar Modelo
```bash
ollama pull llama3.1:8b
```

### 3. Verificar Instalaci√≥n
```bash
npm run check:ollama
```

### 4. Usar en la Aplicaci√≥n
1. Ve al detalle de un cliente
2. Pesta√±a "Objetivos"
3. Haz clic en el bot√≥n "IA"
4. Selecciona n√∫mero de objetivos
5. Haz clic en "Generar objetivos"

## üéØ C√≥mo Funciona

### Flujo de Generaci√≥n

1. **Recopilaci√≥n de Datos**: El sistema recopila toda la informaci√≥n relevante del cliente
2. **Construcci√≥n del Prompt**: Se crea un prompt estructurado con el contexto
3. **Generaci√≥n con IA**: Ollama procesa el prompt y genera objetivos
4. **Validaci√≥n**: Se valida y limpia la respuesta JSON
5. **Guardado**: Los objetivos se guardan en la base de datos

### Prompt de Ejemplo

```
Eres un coach profesional experto en desarrollo personal y profesional.

Necesito que generes 5 objetivos espec√≠ficos y medibles para un cliente bas√°ndote en la siguiente informaci√≥n:

OBJETIVO PRINCIPAL: Mejorar la gesti√≥n del tiempo
ENFOQUE DEL CLIENTE: Productividad y organizaci√≥n
BIOGRAF√çA: Ejecutivo de marketing con 5 a√±os de experiencia...
M√âTRICAS ACTUALES:
- Sesiones completadas: 3
- Calificaci√≥n promedio: 4.2
- √öltima sesi√≥n: 2024-01-15
OBJETIVOS ANTERIORES: Establecer rutina matutina, Priorizar tareas importantes
NOTAS DEL COACH: Cliente muy motivado, necesita estructura clara

INSTRUCCIONES:
1. Genera 5 objetivos espec√≠ficos, medibles y alcanzables
2. Cada objetivo debe estar relacionado con el objetivo principal
3. Considera el progreso actual del cliente
4. Los objetivos deben ser realistas y motivadores
5. Incluye un d√≠a sugerido para cada objetivo

FORMATO DE RESPUESTA (JSON):
[
  {
    "description": "Descripci√≥n del objetivo espec√≠fico y medible",
    "day": "lunes",
    "isCompleted": false
  }
]
```

### Respuesta Esperada

```json
[
  {
    "description": "Implementar t√©cnica Pomodoro durante 2 horas de trabajo diario",
    "day": "lunes",
    "isCompleted": false
  },
  {
    "description": "Crear lista de prioridades semanal cada domingo",
    "day": "domingo",
    "isCompleted": false
  },
  {
    "description": "Eliminar 30 minutos de distracciones digitales diarias",
    "day": "martes",
    "isCompleted": false
  }
]
```

## ‚öôÔ∏è Personalizaci√≥n

### Ajustar Par√°metros de IA

En `src/lib/services/ai-service.ts`:

```typescript
options: {
  temperature: 0.7,    // 0.0-1.0 (creatividad)
  top_p: 0.9,         // 0.0-1.0 (diversidad)
  max_tokens: 1000    // M√°ximo tokens de respuesta
}
```

### Cambiar Modelo

```typescript
model: 'llama3.1:8b', // Cambiar por otro modelo
```

### Modificar Prompt

Puedes personalizar el prompt en el m√©todo `buildPrompt()` para:

- Cambiar el tono de los objetivos
- Agregar m√°s contexto
- Incluir m√©tricas adicionales
- Modificar el formato de respuesta

## üêõ Soluci√≥n de Problemas

### Ollama no responde
```bash
# Verificar estado
npm run check:ollama

# Reiniciar servicio
ollama serve
```

### Generaci√≥n lenta
- Usa modelo m√°s peque√±o: `ollama pull llama3.1:3b`
- Reduce `max_tokens` en la configuraci√≥n
- Reduce `temperature` para respuestas m√°s directas

### Error de memoria
- Cierra otras aplicaciones
- Usa modelo m√°s peque√±o
- Reinicia Ollama

### Objetivos de baja calidad
- Ajusta el prompt para ser m√°s espec√≠fico
- Aumenta `temperature` para m√°s creatividad
- Agrega m√°s contexto en el prompt

## üìä M√©tricas y Monitoreo

### Logs de Generaci√≥n
Los logs se guardan en la consola del servidor:
- Tiempo de generaci√≥n
- Errores de parsing
- Fallbacks a objetivos por defecto

### M√©tricas de Uso
- N√∫mero de objetivos generados
- Tasa de √©xito de generaci√≥n
- Tiempo promedio de respuesta

## üîÆ Futuras Mejoras

### Funcionalidades Planificadas

1. **An√°lisis de Sentimiento**: Evaluar el estado emocional del cliente
2. **Recomendaciones Personalizadas**: Sugerir recursos basados en objetivos
3. **Predicci√≥n de Progreso**: Estimar tiempo para completar objetivos
4. **Generaci√≥n de Contenido**: Crear materiales de apoyo autom√°ticamente
5. **An√°lisis de Patrones**: Identificar tendencias en el progreso

### Modelos Alternativos

- **Mistral 7B**: Mejor rendimiento en espa√±ol
- **CodeLlama**: Para objetivos t√©cnicos
- **Phi-2**: Modelo m√°s peque√±o y r√°pido

## ü§ù Contribuir

### Reportar Bugs
1. Verifica que Ollama est√© funcionando
2. Revisa los logs del servidor
3. Proporciona contexto del error

### Mejorar Prompts
1. Prueba diferentes enfoques
2. Documenta los cambios
3. Comparte resultados

### Agregar Modelos
1. Prueba el modelo localmente
2. Actualiza la documentaci√≥n
3. Ajusta par√°metros seg√∫n sea necesario

## üìû Soporte

Para problemas t√©cnicos:
1. Revisa `OLLAMA_SETUP.md`
2. Ejecuta `npm run check:ollama`
3. Consulta los logs de la aplicaci√≥n
4. Verifica la documentaci√≥n oficial de Ollama

---

**Nota**: Esta funcionalidad requiere Ollama instalado y ejecut√°ndose localmente. Para uso en producci√≥n, considera implementar un servicio de IA en la nube como alternativa. 